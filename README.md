[TOC]

# 推荐系统经典算法

* 协同过滤

# 一. 协同过滤

**仅仅 基于用户行为日志设计的推荐算法**, 在算法分类上, 可以分为以下几类:

* 基于领域的协同过滤算法
* 隐语义模型
* 图的随机游走算法



## 基于领域的协同过滤算法

主要包含下面两种算法, 也是 **工业界运用广泛的两个算法**

- Item-based : 基于物品
- User-based : 基于用户



### 基本思想

利用 和自己兴趣相似的用户, 或者和自己历史感兴趣物品相似的 物品, 来对用户进行推荐

总结来说, 利用别人, 推荐自己

协同过滤可以分为以下两种 : 

基于用户的 : 

* 在众多用户中, 以某种算法找到跟我相似的用户集
* 然后以某种算法对这个用户集进行排序
* **从而相似用户集喜爱的产品, 被推荐人大概率也会喜欢**



基于物品(Item-based)的 :

* 如果我喜爱某一个物品, 那么大概率我会喜欢跟这个 **物品类似的物品**

  注意 ,此时物品的相似, 并不是内容相似, 否则就变成基于内容的了.



#### 基本实现步骤

1. 要了解一个用户, 首先要先收集用户的偏好.

   e.g. 用户 **评分高** 的电影默认为该用户喜欢的电影

2. 找到**相似**的 **用户** 或者 **物品**

3. 计算推荐



#### 用户画像

我们利用收集的用户偏好去表示一个用户, 利用 **向量** 的形式去描述这个用户



#### 相似度评判标准

相似度即为用户求 **物品** , **用户** 之间的 **相似程度** , 该算法的重点在于如何去衡量两个用户或者物品之间的相似度, 衡量方法有几种 : 

* 欧式距离

  这种就是计算两个向量x, y之间的几何距离:

  d(x, y) = $\sqrt{\sum(x_i - y_i)^2}$

  由于距离越近, 我们计算的相似度需要越高, 所以我们的相似度可以表现为欧式距离的倒数:
  Sim(x, y) = $\frac{1}{1+d(x, y)}$

* 🌟 皮尔逊相关系数

  基于协方差 cov(X, Y) 我们用X, Y的协方差除以 X, Y的标准差乘积, 得到X, Y的相关系数:
  Sim(x, y) = $\frac{cov(x, y)}{\sqrt{Var[x] * Var[y]}}$ , 其中, Var[x] 为x的方差. 且 Sim(x, y) $\in$ [-1, 1] .

  这个表示的是X, Y的相关程度, 如果值为 -1 表示x, y完全负相关, 值为 +1 表示正相关, 为 0 表示基本没有关系	

  ~~~
  协方差 cov(x, y) 的求法演示
  cov(x, y) = E(xy) - E(x) * E(y) , 其中 E 为数学期望
  假设 x = [x1, x2, x3] , y = [y1, y2, y3]
  
  求法如下 : 
  E(x) = (x1 + x2 + x3) / 3 
  E(y) = (y1 + y2 + y3) / 3
  E(xy)= (x1*y1 + x2*y2 + x3*y3) / 3
  ~~~


* Consine(余弦) 相似度 

  由余弦定理 : **x** * **y** = |x||y|cos(x, y) 推出的 :

  从而Sim(x, y)  = $\frac{x * y}{|x||y|}$ , 其中 Sim $\in$  [-1, 1], 如果结果为-1那么表式向量完全相反, 为+1表示完全相同



#### 相似物品, 用户数量的选择方案

即假设我们计算一个用户Fz和其他用户相似度之后, 怎么确定我们选择这些相似用户的数量, 即我们应该选择多少用户作为和Fz的相似用户, 有两种方案 :

* 我们选择固定数量 K 的邻居, 从而演变成 K-neighborhoods 算法
* 🌟 我们设定一个相似度门槛 Threshold, 从而选择 **所以小于** 这个门槛的邻居, 从而演变成 Threshold-based neighborhoods 算法

如下图可以显示出两者区别 :

<img src='image/2019-07-16-k-nei.png' style='width:500px'/>





### 基于用户的协同过滤


重温一下, 核心思想为 : 如果A,B相似, 那么B喜欢的东西, A大概率也会喜欢, 从而将B有A没有的东西推荐给A, 以下例子举例 :

| 用户 / 物品 | 物品 A | 物品 B | 物品 C | 物品 D   |
| ----------- | ------ | ------ | ------ | -------- |
| 用户A       | ✅      |        | ✅      | **推荐** |
| 用户B       |        | ✅      |        |          |
| 用户C       | ✅      |        | ✅      | ✅        |

通过相似度可以计算得知 A, C 更为相似, 从而将物品D推荐给用户A



<hr>
**基于用户的协同过滤 有以下步骤**

1. 找到和 目标用户 兴趣相似的 用户集合
2. 找到这个集合中 用户喜欢的, 但是 目标用户没有的 推荐给 目标用户



#### 公式

用户u 对 物品 i 的感兴趣程度为 :

$p(u, i) = \sum _{v \in S(u, K) \cap N(i)} W_{u, v} * R_v $

* p(u, i) 表示用户 u 对 i 的 感兴趣程度
* S(u, K) 表示 和 用户 u 最相似的 K 个用户
* N(i) 表示对 物品 i 有评价的用户
* $W_{u, v}$ 表示 用户u, v 的相似度
* R$_v$  (Ranking) 表示用户 v 对 物品的评分 











#### 基于用户的协同过滤UserCF存在的问题

* 对于一个新的用户, 我们很难去给他做推荐. 因为一个新用户的用户画像矩阵全为0, 没有任何特征, 也就找不出他的相似用户, **这称为用户冷启动问题**
* 对于一个物品推荐与否, 完全取决于相似用户喜欢与否, 太过于绝对



#### 对于基于用户协同过滤 常考虑的优化方法

* 考虑乘以一个系数 CommonRate = min(n, N) / N

  即 A, B用户间共同打分的物品数目除以物品总数. 因为A,B如果共同打分的物品越多, A,B肯定越为相似

* 对物品打分进行 **归一化处理** , 全部归一化到 [0, 1] 的范围内



#### 基于用户的协同过滤在工业上很少用到

* 用户的打分 **矩阵非常稀疏**, 因为一个用户可能就关注过 100 个物品, 但是物品的总数有 100万个, 从而使得这个矩阵非常稀疏!
* 用户群体过于庞大的时候, 计算相似度的效率非常低下 (两两计算的).
* 人是善变的, 从而我们需要去实时的维护这个庞大的稀疏矩阵, 不太现实



### 基于物品的协同过滤🌟 

重温基本思想 : 如果物品 A, B相似, 那么如果 用户Kim喜欢 A, 就可以将 B 也推荐给Kim.

| 用户 / 物品 | 物品 A | 物品 B | 物品 C |
| ----------- | ------ | ------ | ------ |
| 用户A       | ✅      |        | ✅      |
| 用户B       | ✅      | ✅      | ✅      |
| 用户C       | ✅      |        | 推荐   |

即可以算出, 物品 A 和 物品 C 的相似度更高, 从而可以将物品C推荐给用户C

注意, 物品的相似度还是基于大众评分, 并不是基于物品的 内在属性. 

比如 **啤酒** 和 **纸尿裤**, 相似度就可能很高





#### 基于物品的协同过滤的优势 (相比与上一种方法)



**效率方面**

* **计算效率高**, 通常用户的数量远大于物品的数量
* 物品属性并不经常变化, 可以不用实时的维护属性矩阵

<hr>

**冷启动问题方面**

冷启动问题, 





























